# -*- coding: utf-8 -*-
"""Sentiment Latest

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WAekuBWBfnyLnmxeCZ203eeFXIzLYJJN

#  TWITTER SENTIMENT ANALYSIS ON COVID-19 IN MALAYSIA

**Install library**
"""

pip install matplotlib

"""**Import library**"""

import tweepy
from textblob import TextBlob
from wordcloud import WordCloud
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import nltk
import seaborn as sns
from nltk.stem.porter import *
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.linear_model import LogisticRegression
from scipy import stats 
from sklearn import metrics 
from sklearn.metrics import mean_squared_error,mean_absolute_error, make_scorer,classification_report,confusion_matrix,accuracy_score,roc_auc_score,roc_curve
from sklearn.model_selection import train_test_split,cross_val_score,KFold
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
from sklearn.naive_bayes import BernoulliNB
from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
import warnings 
warnings.filterwarnings("ignore")
plt.style.use('fivethirtyeight')

"""**Authentication key from Twitter**"""

# Authentication
#consumerKey = "joRXs4gsNXliJb0aOCqTuF2Pa"
#consumerSecret = "1J8YpCxynexiyW0ygZo9ClETAelqklOYPOCAjNxkLcAwrmRyIv"
#accessToken = "832914904281608192-JYCITkWVwxI4jXKPiSz0dLI5pSKp6vU"
#accessTokenSecret = "152Ew3LbgPve6T72bQ2Zj0FcdMufMJz5zlQtr6uAlP6zi"

#auth = tweepy.OAuthHandler(consumerKey, consumerSecret)
#auth.set_access_token(accessToken, accessTokenSecret)
#api = tweepy.API(auth, wait_on_rate_limit=True)

"""**Search keyword and number of tweet**"""

# extract 5000 tweets

#search_term = 'covid Malaysia'
#tweet_amount = 5000

#tweets = tweepy.Cursor(api.search, q=search_term, lang='en').items(tweet_amount)
#user_locs = [[tweet.user.screen_name, tweet.user.location, tweet.text] for tweet in tweets]


#i=1
#for tweet in tweets:
 # print(str(i) + ') '+ tweet.text + '\n')
  #print(tweet.full_text)
  #i = i+1

# list user, location and tweets 
#df = pd.DataFrame(data=user_locs, columns=['user', 'location', 'tweets'])
df=pd.read_csv('/content/Sentiment_Analysis.csv')

pd.set_option('display.max_colwidth' ,1000)

#df.to_csv (r'C:\Users\hazim\OneDrive\Desktop\AI\PROJECT\Sentiment_Analysis.csv', index = False, header=True)

df

# drop any duplicate tweets
#df = df.drop_duplicates (['tweets'])
#df

# clean text from any username, RT, punctuation and url

def cleanTxt(text):
  text = re.sub(r'@[A-Za-z0-9]+', '', text)
  text = re.sub(r'#','', text)
  text = re.sub(r'RT[\s]+','',text)
  text = re.sub(r'https?:\/\/\S+','', text)
  text = re.sub(r':+', '', text)
  text = re.sub(r'\n', '', text)

  return text

df['tweets']= df['tweets'].apply(cleanTxt)

df

# drop any duplicate tweets
df = df.drop_duplicates (['tweets'])
df

# List out the polarity and subjectivity of each tweets

def getSubjectivity(text):
  return TextBlob(text).sentiment.subjectivity

def getPolarity(text):
  return TextBlob(text).sentiment.polarity

df['Subjectivity'] = df['tweets'].apply(getSubjectivity)
df['Polarity'] = df['tweets'].apply(getPolarity)

df

"""**Understanding the common words used in the tweets**"""

# Plot WordCloud
allWords = ' '.join([twts for twts in df['tweets']])
wordCloud = WordCloud(width = 500, height = 300, random_state = 21, max_font_size = 119).generate(allWords)

plt.imshow(wordCloud, interpolation='bilinear')
plt.axis('off')
plt.show()

# Negative, Positive, Neutral analysis

def getAnalaysis(score):
  if score < 0:
    return 'Negative'
  elif score == 0:
    return 'Neutral'
  else:
    return 'Positive'

df['Sentiments'] =df['Polarity'].apply(getAnalaysis)

df

df['Sentiments'].value_counts()

# Print all of the positive tweets
df[df['Sentiments']=='Positive']

# print all of the negative tweets
df[df['Sentiments']=='Negative']

# Get percentage of positive tweets
ptweets = df[df.Sentiments == 'Positive']
ptweets = ptweets['tweets']

round( (ptweets.shape[0] / df.shape[0]) *100, 1)

# Get percentage of negative tweets
ntweets = df[df.Sentiments == 'Negative']
ntweets = ntweets['tweets']

round( (ntweets.shape[0] / df.shape[0]) *100, 1)

# Show value count
df['Sentiments'].value_counts()

# plot and visualize the counts
plt.title('Sentiment Analysis')
plt.xlabel('Sentiment')
plt.ylabel('Counts')
df['Sentiments'].value_counts().plot(kind='bar')
plt.show()

# show value count
df['Sentiments'].value_counts()

# plot and visualize the counts
plt.title('Sentiment Analysis ')
plt.xlabel('Sentiment')
plt.ylabel('Counts')
df['Sentiments'].value_counts().plot(kind='pie')
plt.show()

# Plot polarity and subjectivity
plt.figure(figsize=(8,6))

plt.scatter(df['Polarity'],df['Subjectivity'], color='Blue')

plt.title('Sentiment Analysis')
plt.xlabel('Polarity')
plt.ylabel('Subjectivity')
plt.show()

"""## Extracting features from cleaned tweets"""

new_df = df[['tweets','Sentiments']]
new_df.head()

"""**Removing stopwords**"""

nltk.download('stopwords')

from nltk.corpus import stopwords
stop = stopwords.words('english')

new_df['tweets'].apply(lambda x: [item for item in x if item not in stop])

new_df.head(6)

new_df['Sentiments'].value_counts()

"""# **LOGISTIC REGRESSION (MULTICLASS CLASSIFICATION)**

**Split train and test dataset**
"""

from sklearn.model_selection import train_test_split

train,valid = train_test_split(new_df,test_size = 0.2,random_state=0,stratify = new_df.Sentiments.values) #stratification means that the train_test_split method returns training and test subsets that have the same proportions of class labels as the input dataset.
print("train shape : ", train.shape)
print("valid shape : ", valid.shape)

"""# Use Of Counter Vectorizer For Multi Class Classification"""

from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords
stop = list(stopwords.words('english'))
vectorizer = CountVectorizer(decode_error = 'replace',stop_words = stop)

X_train = vectorizer.fit_transform(train.tweets.values)
X_valid = vectorizer.transform(valid.tweets.values)

y_train = train.Sentiments.values
y_valid = valid.Sentiments.values

print("X_train.shape : ", X_train.shape)
print("X_valid.shape : ", X_valid.shape)
print("y_train.shape : ", y_train.shape)
print("y_valid.shape : ", y_valid.shape)

"""# Logistic Regression(For Multiclass Classification)"""

from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()

logreg.fit(X_train, y_train)

logreg_prediction = logreg.predict(X_valid)
number_itter=logreg.n_iter_
logreg_accuracy = accuracy_score(y_valid,logreg_prediction)
print("Training accuracy Score    : ",logreg.score(X_train,y_train))
print("Validation accuracy Score : ",logreg_accuracy )
print("Number of Iteration : ", number_itter)
print(classification_report(logreg_prediction,y_valid))

"""# CONVERTING MULTICLASS CLASSIFICATION INTO BINARY CLASSIFICATION"""

new_df.head()

new_df.shape

log_reg = new_df[['tweets','Sentiments']]

log_reg.head()

log_reg["Sentiments"]= log_reg["Sentiments"].replace('Positive',1) 
log_reg["Sentiments"]= log_reg["Sentiments"].replace('Neutral',1) 
log_reg["Sentiments"]= log_reg["Sentiments"].replace('Negative',0)

log_reg.head()

log_reg['Sentiments'].value_counts()

X = log_reg.drop('Sentiments', axis=1)
y = log_reg.Sentiments

"""**Removing stopwords**"""

nltk.download('stopwords')

from nltk.corpus import stopwords
stop = stopwords.words('english')

log_reg['tweets'].apply(lambda x: [item for item in x if item not in stop])

"""# **LOGISTIC REGRESSION (BINARY CLASSIFICATION)**

**Split train and test dataset**
"""

from sklearn.model_selection import train_test_split

train,valid = train_test_split(log_reg,test_size = 0.2,random_state=0,stratify = log_reg.Sentiments.values) #stratification means that the train_test_split method returns training and test subsets that have the same proportions of class labels as the input dataset.
print("train shape : ", train.shape)
print("valid shape : ", valid.shape)

"""# Use Of Count Vectorizer For Binary Classification"""

from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords
stop = list(stopwords.words('english'))
vectorizer = CountVectorizer(decode_error = 'replace',stop_words = stop)

X_train = vectorizer.fit_transform(train.tweets.values)
X_valid = vectorizer.transform(valid.tweets.values)

y_train = train.Sentiments.values
y_valid = valid.Sentiments.values

print("X_train.shape : ", X_train.shape)
print("X_valid.shape : ", X_valid.shape)
print("y_train.shape : ", y_train.shape)
print("y_valid.shape : ", y_valid.shape)

"""# Logistic Regression(For Binary Classification)"""

from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()

logreg.fit(X_train, y_train)

logreg_prediction = logreg.predict(X_valid)
number_itter=logreg.n_iter_
logreg_accuracy = accuracy_score(y_valid,logreg_prediction)
print("Training accuracy Score    : ",logreg.score(X_train,y_train))
print("Validation accuracy Score : ",logreg_accuracy )
print("number of Iteration : ", number_itter)
print(classification_report(logreg_prediction,y_valid))

# Get the predicted classes
train_class_preds = logreg.predict(X_train)
test_class_preds = logreg.predict(X_valid)

# Get the confusion matrix for train

labels = ['Negative', 'Positive']
cm = confusion_matrix(train_class_preds, y_train )
print(cm)

ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells

# labels, title and ticks
ax.set_xlabel('Predicted labels')
ax.set_ylabel('Actual labels')
ax.set_title('Confusion Matrix')
ax.xaxis.set_ticklabels(labels)
ax.yaxis.set_ticklabels(labels)

# Get the confusion matrix for test

labels = ['Negative', 'Positive']
cm = confusion_matrix( test_class_preds, y_valid)
print(cm)

ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells

# labels, title and ticks
ax.set_xlabel('Predicted labels')
ax.set_ylabel('Actual labels')
ax.set_title('Confusion Matrix')
ax.xaxis.set_ticklabels(labels)
ax.yaxis.set_ticklabels(labels)

# Let's check the overall accuracy. Overall accuracy is very good.
from sklearn.metrics import accuracy_score
from sklearn.metrics import log_loss

y_pred = logreg.predict(X_valid)

score =accuracy_score(y_valid,y_pred)
print('accuracy is', score)

# F1 score for our classifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix


y_pred =  logreg.predict(X_valid)
print(f1_score(y_valid,y_pred, average="macro"))

# Score is mean accuracy
scikit_score = logreg.score(X_valid,y_valid)
print('scikit score:', scikit_score)

TP = 199
FP = 5
# FN (0) and TN (12) are not needed in the formuala!
precision = TP / (TP + FP)
print(f"precision: {precision:4.2f}")

TP = 199
FN = 17
# FT (14) and TN (12) are not needed in the formuala!
recall = TP / (TP + FN)
print(f"recall: {recall:4.2f}")